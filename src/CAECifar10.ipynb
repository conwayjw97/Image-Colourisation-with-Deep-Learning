{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAECifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVxRHY+TB9YmE68bmjF78J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conwayjw97/Image-Colourisation/blob/master/src/CAECifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-tnptjPCke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, Lambda, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.datasets import cifar10, mnist\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# !pip install talos\n",
        "import talos as ta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ-SYyyxPCOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "class_train_indices = np.argwhere(train_labels == 0)\n",
        "class_train_images = train_images[class_train_indices[:,0]]\n",
        "class_test_indices = np.argwhere(test_labels == 0)\n",
        "class_test_images = test_images[class_test_indices[:,0]]\n",
        "\n",
        "train_yuvImages = tf.image.rgb_to_yuv(class_train_images)\n",
        "train_y = tf.expand_dims(train_yuvImages[:,:,:,0], 3)\n",
        "train_uv = train_yuvImages[:,:,:,1:]\n",
        "\n",
        "test_yuvImages = tf.image.rgb_to_yuv(class_test_images)\n",
        "test_y = tf.expand_dims(test_yuvImages[:,:,:,0], 3)\n",
        "test_uv = test_yuvImages[:,:,:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LQzlzMCOIC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder_deconv.py\n",
        "\n",
        "def autoencoder_model(train_y, train_uv, test_y, test_uv, parameters):\n",
        "  batch_size = parameters['batch_size']\n",
        "  kernel_size = 3\n",
        "  latent_dim = parameters['latent_dim']\n",
        "  epochs = 100\n",
        "\n",
        "  # Define Encoder\n",
        "  inputs = Input(shape=(train_y.shape[1], train_y.shape[2], train_y.shape[3]))\n",
        "  layer = inputs\n",
        "  layer = Conv2D(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  layer = Conv2D(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  layer = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  layer = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  shape = K.int_shape(layer) # Shape before flattening\n",
        "\n",
        "  # Latent space\n",
        "  layer = Flatten()(layer)\n",
        "  latent = Dense(latent_dim)(layer)\n",
        "\n",
        "  # Instantiate Encoder\n",
        "  encoder = Model(inputs, latent, name='encoder')\n",
        "  encoder.summary()\n",
        "\n",
        "  # Define Decoder\n",
        "  latent_inputs = Input(shape=(latent_dim,))\n",
        "  layer = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "  layer = Reshape((shape[1], shape[2], shape[3]))(layer)\n",
        "  layer = Conv2DTranspose(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  layer = Conv2DTranspose(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  layer = Conv2DTranspose(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  layer = Conv2DTranspose(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "  outputs = Conv2DTranspose(filters=2, kernel_size=kernel_size, activation='sigmoid', padding='same')(layer)\n",
        "\n",
        "  # Instantiate Decoder\n",
        "  decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "  decoder.summary()\n",
        "\n",
        "  # Autoencoder\n",
        "  autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "  autoencoder.summary()\n",
        "\n",
        "  # Reduce learning rate by sqrt(0.1) if the loss does not improve in 5 epochs\n",
        "  lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                                cooldown=0,\n",
        "                                patience=5,\n",
        "                                verbose=1,\n",
        "                                min_lr=0.5e-6)\n",
        "\n",
        "  # Define loss\n",
        "  opt = RMSprop(lr=parameters['lr'], momentum=parameters['momentum'])\n",
        "  # autoencoder.compile(loss='mse', optimizer='adam')\n",
        "  autoencoder.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "  # Train\n",
        "  history = autoencoder.fit(train_y, train_uv, validation_data=(test_y, test_uv), epochs=epochs, batch_size=batch_size, callbacks=[])\n",
        "\n",
        "  return history, autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-aOssy6zlxh",
        "colab_type": "code",
        "outputId": "17bce8fe-6107-4966-c44c-a1999e1acc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "parameters = {\n",
        "    'batch_size': [128, 256, 512],\n",
        "    'latent_dim': [128, 256, 512],\n",
        "    'lr': [0.001, 0.0001, 0.00001],\n",
        "    'momentum': [0.0, 0.25, 0.5]\n",
        "}\n",
        "\n",
        "scan_results = ta.Scan(train_y, train_uv, parameters, autoencoder_model, \"Autoencoder optimisation\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-36b0c7894339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mscan_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_uv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Autoencoder optimisation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# start runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_run\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mscan_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_prepare\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# initiate the progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/scan_prepare.py\u001b[0m in \u001b[0;36mscan_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# handle validation split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# set data and len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/utils/validation_split.py\u001b[0m in \u001b[0;36mvalidation_split\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# shuffle the data before splitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrandom_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# deduce the midway point for input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/utils/validation_split.py\u001b[0m in \u001b[0;36mrandom_shuffle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([3717, 3100, 3864, ..., 3985, 2612,  221])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3qHYsgo0V3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dCCE3I_AqfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = autoencoder.predict(test_y)\n",
        "result = np.zeros((test_yuvImages.shape[0], 32, 32, 3))\n",
        "result[:,:,:,0] = test_y[:,:,:,0]\n",
        "result[:,:,:,1:] = output\n",
        "\n",
        "output_count = 12\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"Input\")\n",
        "  plt.imshow(tf.image.grayscale_to_rgb(test_y[i]))\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"Original\")\n",
        "  plt.imshow(class_test_images[i])\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"Output\")\n",
        "  plt.imshow(tf.image.yuv_to_rgb(result[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFFLKyy_q3QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}