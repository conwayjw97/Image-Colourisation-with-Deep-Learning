{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVAEBojoneCNNCifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPb0heQQI43kAILmCMf23Eq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conwayjw97/Image-Colourisation/blob/master/src/CVAEBojoneCNNCifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-tnptjPCke",
        "colab_type": "code",
        "outputId": "8151d4de-57e0-4e24-cea3-70105be5f15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, Lambda, Reshape, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.datasets import cifar10, mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ-SYyyxPCOf",
        "colab_type": "code",
        "outputId": "8047a35a-85a3-449e-fa36-b9ae0678c203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "class_train_indices = np.argwhere(train_labels == 0)\n",
        "class_train_images = train_images[class_train_indices[:,0]]\n",
        "class_test_indices = np.argwhere(test_labels == 0)\n",
        "class_test_images = test_images[class_test_indices[:,0]]\n",
        "\n",
        "train_yuvImages = tf.image.rgb_to_yuv(class_train_images)\n",
        "train_y = tf.expand_dims(train_yuvImages[:,:,:,0], 3)\n",
        "train_uv = train_yuvImages[:,:,:,1:]\n",
        "\n",
        "test_yuvImages = tf.image.rgb_to_yuv(class_test_images)\n",
        "test_y = tf.expand_dims(test_yuvImages[:,:,:,0], 3)\n",
        "test_uv = test_yuvImages[:,:,:,1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm965tiF2uPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LQzlzMCOIC6",
        "colab_type": "code",
        "outputId": "b2b24d17-25ea-415c-8c7c-75ad26f75dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder_deconv.py\n",
        "# https://xiangyutang2.github.io/auto-colorization-autoencoders/\n",
        "\n",
        "# (x_train, y_train_), (x_test, y_test_) = mnist.load_data()\n",
        "\n",
        "# image_size = x_train.shape[1]\n",
        "# x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "# x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
        "# x_train = x_train.astype('float32') / 255\n",
        "# x_test = x_test.astype('float32') / 255\n",
        "\n",
        "batch_size = 100\n",
        "kernel_size = 3\n",
        "filters = 64\n",
        "latent_dim = 2\n",
        "# latent_dim = 512\n",
        "epochs = 30\n",
        "\n",
        "# Sampling with the reparametrisation trick\n",
        "def sample(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=K.shape(z_mean))\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# Define Training Encoder q(z|uv,y)\n",
        "yuv_in = Input(shape=(train_yuvImages.shape[1], train_yuvImages.shape[2], train_yuvImages.shape[3]))\n",
        "layer = Conv2D(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(yuv_in)\n",
        "layer = Conv2D(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "shape = K.int_shape(layer) # Shape before flattening\n",
        "\n",
        "# Latent space for training encoder\n",
        "layer = Flatten()(layer)\n",
        "layer = Dense(16, activation='relu')(layer)\n",
        "z_mean_training = Dense(latent_dim)(layer)\n",
        "z_log_var_training = Dense(latent_dim)(layer)\n",
        "z_training = Lambda(sample, output_shape=(latent_dim,))([z_mean_training, z_log_var_training]) # Data passable to the decoder\n",
        "\n",
        "# Instantiate training encoder \n",
        "encoder_training = Model(yuv_in, z_training, name='training encoder')\n",
        "encoder_training.summary()\n",
        "\n",
        "# Define Conditional Encoder p(z|y)\n",
        "y_in = Input(shape=(train_y.shape[1], train_y.shape[2], train_y.shape[3]))\n",
        "layer = Conv2D(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(y_in)\n",
        "layer = Conv2D(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "shapeConditional = K.int_shape(layer) # Shape before flattening\n",
        "\n",
        "# Latent space for conditional encoder\n",
        "layer = Flatten()(layer)\n",
        "layer = Dense(16, activation='relu')(layer)\n",
        "z_mean_conditional = Dense(latent_dim)(layer)\n",
        "z_log_var_conditional = Dense(latent_dim)(layer)\n",
        "z_conditional = Lambda(sample, output_shape=(latent_dim,))([z_mean_conditional, z_log_var_conditional]) # Data passable to the decoder\n",
        "\n",
        "# Instantiate conditional encoder\n",
        "encoder_conditional = Model(y_in, z_conditional, name='conditional encoder')\n",
        "encoder_conditional.summary()\n",
        "\n",
        "\n",
        "# Define Decoder p(uv|z,y)\n",
        "latent_inputs = Input(shape=(latent_dim,))\n",
        "layer = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "layer = Reshape((shape[1], shape[2], shape[3]))(layer)\n",
        "layer = Conv2DTranspose(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "uv_out = Conv2DTranspose(filters=2, kernel_size=kernel_size, activation='sigmoid', padding='same')(layer)\n",
        "# Why would it concatenate the y_in with uv_out to produce another uv_mean?\n",
        "# concat = tf.keras.layers.Concatenate(axis=1)([l1, l2]) # Better concatenation?\n",
        "# out = tf.keras.layers.Dense(10)(concat)\n",
        "concat_outputs = concatenate([uv_out, y_in], 3)\n",
        "layer = Conv2DTranspose(filters=8, kernel_size=kernel_size, activation='relu', padding='same')(concat_outputs)\n",
        "mean_yuv = Conv2DTranspose(filters=3, kernel_size=kernel_size, activation='sigmoid', padding='same')(layer)\n",
        "log_sig_sqr_yuv = Conv2DTranspose(filters=3, kernel_size=kernel_size, activation='relu', padding='same')(layer)\n",
        "\n",
        "# Instantiate Decoder\n",
        "decoder = Model([latent_inputs, y_in], [mean_yuv, log_sig_sqr_yuv], name='decoder')\n",
        "# decoder = Model(latent_inputs, [mean_yuv, log_sig_sqr_yuv])\n",
        "decoder.summary()\n",
        "training_decoder = decoder([z_training, y_in])\n",
        "sampling_decoder = decoder([z_conditional, y_in])\n",
        "\n",
        "# COST FROM RECONSTRUCTION\n",
        "SMALL_CONSTANT = 1e-6\n",
        "normalising_factor_uv_vae = - 0.5 * K.log(SMALL_CONSTANT+K.exp(log_sig_sqr_yuv)) - 0.5 * K.log(2 * np.pi)\n",
        "square_diff_between_mu_and_yuv_vae = K.square(mean_yuv - yuv_in) # yuv_in???\n",
        "# inside_exp_x_vae = -0.5 * K.divide(square_diff_between_mu_and_yuv_vae,SMALL_CONSTANT+tf.exp(log_sig_sqr_yuv))\n",
        "inside_exp_x_vae = -0.5 * (square_diff_between_mu_and_yuv_vae / (SMALL_CONSTANT+tf.exp(log_sig_sqr_yuv)))\n",
        "# reconstr_loss_x_vae = -K.reduce_sum(normalising_factor_uv_vae + inside_exp_x_vae, 1)\n",
        "reconstr_loss_x_vae = -K.sum(normalising_factor_uv_vae + inside_exp_x_vae, 1)\n",
        "# cost_R_vae = K.reduce_mean(reconstr_loss_x_vae)\n",
        "cost_R_vae = K.mean(reconstr_loss_x_vae)\n",
        "\n",
        "# KL(q(z|uv,y)||p(z|y))\n",
        "v_mean = z_mean_conditional #2\n",
        "aux_mean = z_mean_training #1\n",
        "v_log_sig_sq = K.log(K.exp(z_log_var_conditional)+SMALL_CONSTANT) #2\n",
        "aux_log_sig_sq = K.log(K.exp(z_log_var_training)+SMALL_CONSTANT) #1\n",
        "v_log_sig = K.log(K.sqrt(K.exp(v_log_sig_sq))) #2\n",
        "aux_log_sig = K.log(K.sqrt(K.exp(aux_log_sig_sq))) #1\n",
        "# cost_VAE_a = v_log_sig-aux_log_sig+K.divide(K.exp(aux_log_sig_sq)+K.square(aux_mean-v_mean),2*K.exp(v_log_sig_sq))-0.5\n",
        "cost_VAE_a = v_log_sig-aux_log_sig+((K.exp(aux_log_sig_sq)+K.square(aux_mean-v_mean))/(2*K.exp(v_log_sig_sq)))-0.5\n",
        "# cost_VAE_b = K.reduce_sum(cost_VAE_a,1)\n",
        "cost_VAE_b = K.sum(cost_VAE_a,1)\n",
        "# KL_vae = K.reduce_mean(cost_VAE_b)\n",
        "KL_vae = K.mean(cost_VAE_b)\n",
        "\n",
        "# VAE\n",
        "vae = Model(inputs=[yuv_in, y_in], outputs=training_decoder)\n",
        "# vae.add_loss(K.sum(cost_R_vae, KL_vae))\n",
        "vae.add_loss(K.sum(cost_R_vae + KL_vae))\n",
        "vae.compile(optimizer='rmsprop')\n",
        "\n",
        "# xent_loss = K.sum(K.mean_squared_error(x_in, x_out), axis=[1, 2, 3]) \n",
        "# kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "# vae_loss = K.mean(xent_loss + kl_loss)\n",
        "# vae.add_loss(vae_loss)\n",
        "# vae.compile(optimizer='rmsprop')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"training encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 8)    224         input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 2, 2, 64)     18496       conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 256)          0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 16)           4112        flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 2)            34          dense_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 2)            34          dense_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 2)            0           dense_36[0][0]                   \n",
            "                                                                 dense_37[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 28,708\n",
            "Trainable params: 28,708\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"conditional encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 8)    80          input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 2, 2, 64)     18496       conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 256)          0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 16)           4112        flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 2)            34          dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 2)            34          dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 2)            0           dense_39[0][0]                   \n",
            "                                                                 dense_40[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 28,564\n",
            "Trainable params: 28,564\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 256)          768         input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 2, 2, 64)     0           dense_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_40 (Conv2DTran (None, 4, 4, 64)     36928       reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_41 (Conv2DTran (None, 8, 8, 32)     18464       conv2d_transpose_40[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_42 (Conv2DTran (None, 16, 16, 16)   4624        conv2d_transpose_41[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_43 (Conv2DTran (None, 32, 32, 8)    1160        conv2d_transpose_42[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_44 (Conv2DTran (None, 32, 32, 2)    146         conv2d_transpose_43[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "input_17 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 3)    0           conv2d_transpose_44[0][0]        \n",
            "                                                                 input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_45 (Conv2DTran (None, 32, 32, 8)    224         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_46 (Conv2DTran (None, 32, 32, 3)    219         conv2d_transpose_45[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_47 (Conv2DTran (None, 32, 32, 3)    219         conv2d_transpose_45[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 62,752\n",
            "Trainable params: 62,752\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_5\" was not an Input tensor, it was generated by layer input_17.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_17:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dffff0016c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myuv_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# vae.add_loss(K.sum(cost_R_vae, KL_vae))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_R_vae\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mKL_vae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_loss\u001b[0;34m(self, losses, inputs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msymbolic_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbolic_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_graph_network'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m           \u001b[0;31m# Possible a loss was added in a Layer's `build`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_graph_network_add_loss\u001b[0;34m(self, symbolic_loss)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m     \u001b[0mnew_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_subgraph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m     \u001b[0;31m# Losses must be keyed on inputs no matter what in order to be supported in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;31m# DistributionStrategy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_subgraph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1702\u001b[0m   \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m   \u001b[0;31m# Keep only nodes and layers in the topology betweeen inputs and outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_18:0\", shape=(None, 2), dtype=float32) at layer \"input_18\". The following previous layers were accessed without issue: ['input_16', 'input_17', 'conv2d_40', 'conv2d_44']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftGcL0gHbpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "# vae.fit(x_train, shuffle=True, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None)) # MNIST version\n",
        "vae.fit(train_uv, shuffle=True, epochs=epochs, batch_size=batch_size, validation_data=(test_uv, None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7OHmeu_KBm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder = Model(x_in, z_mean)\n",
        "\n",
        "# x_test_encoded = encoder.predict(x_test, batch_size=batch_size) \n",
        "# plt.figure(figsize=(6, 6))\n",
        "# plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=test_y)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "# n = 15  # figure with 15x15 digits\n",
        "# digit_size = 28\n",
        "# figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "# grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "# grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "# for i, yi in enumerate(grid_x):\n",
        "#     for j, xi in enumerate(grid_y):\n",
        "#         z_sample = np.array([[xi, yi]])\n",
        "#         x_decoded = decoder.predict(z_sample)\n",
        "#         digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "#         figure[i * digit_size: (i + 1) * digit_size,\n",
        "#                j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# plt.imshow(figure, cmap='Greys_r')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}