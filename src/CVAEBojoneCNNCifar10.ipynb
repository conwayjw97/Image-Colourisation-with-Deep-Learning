{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVAEBojoneCNNCifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHABfzNmwmZBLn7gCUdL6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conwayjw97/Image-Colourisation/blob/master/src/CVAEBojoneCNNCifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-tnptjPCke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, Lambda, Reshape, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.datasets import cifar10, mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ-SYyyxPCOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "class_train_indices = np.argwhere(train_labels == 0)\n",
        "class_train_images = train_images[class_train_indices[:,0]]\n",
        "class_test_indices = np.argwhere(test_labels == 0)\n",
        "class_test_images = test_images[class_test_indices[:,0]]\n",
        "\n",
        "train_yuvImages = tf.image.rgb_to_yuv(class_train_images)\n",
        "train_y = tf.expand_dims(train_yuvImages[:,:,:,0], 3)\n",
        "train_uv = train_yuvImages[:,:,:,1:]\n",
        "\n",
        "test_yuvImages = tf.image.rgb_to_yuv(class_test_images)\n",
        "test_y = tf.expand_dims(test_yuvImages[:,:,:,0], 3)\n",
        "test_uv = test_yuvImages[:,:,:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LQzlzMCOIC6",
        "colab_type": "code",
        "outputId": "73ca78e6-e46d-4a4f-9f0b-2fcfe9518c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder_deconv.py\n",
        "\n",
        "# (x_train, y_train_), (x_test, y_test_) = mnist.load_data()\n",
        "\n",
        "# image_size = x_train.shape[1]\n",
        "# x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "# x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
        "# x_train = x_train.astype('float32') / 255\n",
        "# x_test = x_test.astype('float32') / 255\n",
        "\n",
        "batch_size = 100\n",
        "kernel_size = 3\n",
        "filters = 64\n",
        "# latent_dim = 2\n",
        "latent_dim = 512\n",
        "epochs = 30\n",
        "\n",
        "# Sampling with the reparametrisation trick\n",
        "def sample(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=K.shape(z_mean))\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# Define Training Encoder q(z|uv,y)\n",
        "yuv_in = Input(shape=(train_yuvImages.shape[1], train_yuvImages.shape[2], train_yuvImages.shape[3]))\n",
        "layer = yuv_in\n",
        "layer = Conv2D(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "shape = K.int_shape(layer) # Shape before flattening\n",
        "\n",
        "# Latent space for training encoder\n",
        "layer = Flatten()(layer)\n",
        "layer = Dense(16, activation='relu')(layer)\n",
        "z_mean_training = Dense(latent_dim)(layer)\n",
        "z_log_var_training = Dense(latent_dim)(layer)\n",
        "z_training = Lambda(sample, output_shape=(latent_dim,))([z_mean_training, z_log_var_training]) # Data passable to the decoder\n",
        "\n",
        "# Instantiate training encoder \n",
        "encoder_training = Model(yuv_in, [z_mean_training, z_log_var_training, z_training], name='encoder')\n",
        "encoder_training.summary()\n",
        "\n",
        "# Define Conditional Encoder p(z|y)\n",
        "y_in = Input(shape=(train_y.shape[1], train_y.shape[2], train_y.shape[3]))\n",
        "layer = y_in\n",
        "layer = Conv2D(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "shapeConditional = K.int_shape(layer) # Shape before flattening\n",
        "\n",
        "# Latent space for conditional encoder\n",
        "layer = Flatten()(layer)\n",
        "layer = Dense(16, activation='relu')(layer)\n",
        "z_mean_conditional = Dense(latent_dim)(layer)\n",
        "z_log_var_conditional = Dense(latent_dim)(layer)\n",
        "z_conditional = Lambda(sample, output_shape=(latent_dim,))([z_mean_conditional, z_log_var_conditional]) # Data passable to the decoder\n",
        "\n",
        "# Instantiate conditional encoder\n",
        "encoder_training = Model(y_in, [z_mean_conditional, z_log_var_conditional, z_conditional], name='encoder')\n",
        "encoder_training.summary()\n",
        "\n",
        "\n",
        "# Define Decoder p(uv|z,y)\n",
        "latent_inputs = Input(shape=(latent_dim,))\n",
        "layer = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "layer = Reshape((shape[1], shape[2], shape[3]))(layer)\n",
        "layer = Conv2DTranspose(filters=64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=16, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=8, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(layer)\n",
        "uv_out = Conv2DTranspose(filters=2, kernel_size=kernel_size, activation='sigmoid', padding='same')(layer)\n",
        "\n",
        "concat_outputs = concatenate([uv_out, y_in], 3)\n",
        "layer = Conv2DTranspose(filters=8, kernel_size=kernel_size, activation='relu', padding='same')(concat_outputs)\n",
        "mean_yuv = Conv2DTranspose(filters=2, kernel_size=kernel_size, activation='sigmoid', padding='same')(layer)\n",
        "log_sig_sqr_yuv = Conv2DTranspose(filters=2, kernel_size=kernel_size, activation='relu', padding='same')(layer)\n",
        "\n",
        "# Instantiate Decoder\n",
        "decoder = Model([latent_inputs, y_in], [mean_yuv, log_sig_sqr_yuv])\n",
        "decoder.summary()\n",
        "\n",
        "# COST FROM RECONSTRUCTION\n",
        "SMALL_CONSTANT = 1e-6\n",
        "normalising_factor_uv_vae = - 0.5 * K.log(SMALL_CONSTANT+K.exp(log_sig_sqr_yuv)) - 0.5 * K.log(2 * np.pi)\n",
        "square_diff_between_mu_and_x_vae = K.square(mean_yuv - yuv_in) # yuv_in???\n",
        "inside_exp_x_vae = -0.5 * K.div(square_diff_between_mu_and_x_vae,SMALL_CONSTANT+tf.exp(log_sig_sqr_yuv))\n",
        "reconstr_loss_x_vae = -K.reduce_sum(normalising_factor_uv_vae + inside_exp_x_vae, 1)\n",
        "cost_R_vae = K.reduce_mean(reconstr_loss_x_vae)\n",
        "\n",
        "# KL(q(z|uv,y)||p(z|y))\n",
        "v_mean = z_mean_conditional #2\n",
        "aux_mean = z_mean_training #1\n",
        "v_log_sig_sq = K.log(K.exp(z_log_var_conditional)+SMALL_CONSTANT) #2\n",
        "aux_log_sig_sq = K.log(K.exp(z_log_var_training)+SMALL_CONSTANT) #1\n",
        "v_log_sig = K.log(K.sqrt(K.exp(v_log_sig_sq))) #2\n",
        "aux_log_sig = K.log(K.sqrt(K.exp(aux_log_sig_sq))) #1\n",
        "cost_VAE_a = v_log_sig-aux_log_sig+K.divide(K.exp(aux_log_sig_sq)+K.square(aux_mean-v_mean),2*K.exp(v_log_sig_sq))-0.5\n",
        "cost_VAE_b = K.reduce_sum(cost_VAE_a,1)\n",
        "KL_vae = K.reduce_mean(cost_VAE_b)\n",
        "\n",
        "# VAE\n",
        "vae = Model(yuv_in, y_in, [mean_yuv, log_sig_sqr_yuv])\n",
        "vae.add_loss(K.sum(cost_R_vae, KL_vae))\n",
        "vae.compile(optimizer='rmsprop')\n",
        "\n",
        "# xent_loss = K.sum(K.mean_squared_error(x_in, x_out), axis=[1, 2, 3]) \n",
        "# kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "# vae_loss = K.mean(xent_loss + kl_loss)\n",
        "# vae.add_loss(vae_loss)\n",
        "# vae.compile(optimizer='rmsprop')\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_28 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 16, 16, 8)    224         input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 2, 2, 64)     18496       conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_19 (Flatten)            (None, 256)          0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_65 (Dense)                (None, 16)           4112        flatten_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_66 (Dense)                (None, 512)          8704        dense_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_67 (Dense)                (None, 512)          8704        dense_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 512)          0           dense_66[0][0]                   \n",
            "                                                                 dense_67[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 46,048\n",
            "Trainable params: 46,048\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 16, 16, 8)    80          input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 2, 2, 64)     18496       conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_20 (Flatten)            (None, 256)          0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_68 (Dense)                (None, 16)           4112        flatten_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_69 (Dense)                (None, 512)          8704        dense_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_70 (Dense)                (None, 512)          8704        dense_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 512)          0           dense_69[0][0]                   \n",
            "                                                                 dense_70[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 45,904\n",
            "Trainable params: 45,904\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_71 (Dense)                (None, 256)          131328      input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 2, 2, 64)     0           dense_71[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_53 (Conv2DTran (None, 4, 4, 64)     36928       reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_54 (Conv2DTran (None, 8, 8, 32)     18464       conv2d_transpose_53[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_55 (Conv2DTran (None, 16, 16, 16)   4624        conv2d_transpose_54[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_56 (Conv2DTran (None, 32, 32, 8)    1160        conv2d_transpose_55[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_57 (Conv2DTran (None, 32, 32, 2)    146         conv2d_transpose_56[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "input_29 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 3)    0           conv2d_transpose_57[0][0]        \n",
            "                                                                 input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_58 (Conv2DTran (None, 32, 32, 8)    224         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_59 (Conv2DTran (None, 32, 32, 2)    146         conv2d_transpose_58[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_60 (Conv2DTran (None, 32, 32, 2)    146         conv2d_transpose_58[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 193,166\n",
            "Trainable params: 193,166\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1618\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 2 and 3 for 'sub_1' (op: 'Sub') with input shapes: [?,32,32,2], [?,32,32,3].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-81252d08b17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mSMALL_CONSTANT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mnormalising_factor_uv_vae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMALL_CONSTANT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_sig_sqr_yuv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0msquare_diff_between_mu_and_x_vae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_yuv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myuv_in\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# yuv_in???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0minside_exp_x_vae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquare_diff_between_mu_and_x_vae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSMALL_CONSTANT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_sig_sqr_yuv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mreconstr_loss_x_vae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalising_factor_uv_vae\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minside_exp_x_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  10102\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10103\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m> 10104\u001b[0;31m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m  10105\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3322\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1786\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 2 and 3 for 'sub_1' (op: 'Sub') with input shapes: [?,32,32,2], [?,32,32,3]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftGcL0gHbpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "# vae.fit(x_train, shuffle=True, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None)) # MNIST version\n",
        "vae.fit(train_uv, shuffle=True, epochs=epochs, batch_size=batch_size, validation_data=(test_uv, None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7OHmeu_KBm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder = Model(x_in, z_mean)\n",
        "\n",
        "# x_test_encoded = encoder.predict(x_test, batch_size=batch_size) \n",
        "# plt.figure(figsize=(6, 6))\n",
        "# plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=test_y)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "# n = 15  # figure with 15x15 digits\n",
        "# digit_size = 28\n",
        "# figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "# grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "# grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "# for i, yi in enumerate(grid_x):\n",
        "#     for j, xi in enumerate(grid_y):\n",
        "#         z_sample = np.array([[xi, yi]])\n",
        "#         x_decoded = decoder.predict(z_sample)\n",
        "#         digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "#         figure[i * digit_size: (i + 1) * digit_size,\n",
        "#                j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# plt.imshow(figure, cmap='Greys_r')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYmoL9XALF29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dCCE3I_AqfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}