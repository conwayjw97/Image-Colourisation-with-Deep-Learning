{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVAECifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/I9e5wi1i8JH5q3gO6yny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conwayjw97/Image-Colourisation/blob/master/src/CVAECifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3jaFgBtcSXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "LATENT_DIM = 2\n",
        "EPOCHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLS6_8rmbeK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from scipy.stats import norm\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, Lambda, Reshape, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLT9fCbFbs5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "class_index = 6\n",
        "\n",
        "class_train_indices = np.argwhere(train_labels == class_index)\n",
        "class_train_images = train_images[class_train_indices[:,0]]\n",
        "class_test_indices = np.argwhere(test_labels == class_index)\n",
        "class_test_images = test_images[class_test_indices[:,0]]\n",
        "\n",
        "train_yuv  = tf.image.rgb_to_yuv(class_train_images)\n",
        "train_y = tf.expand_dims(train_yuv[:,:,:,0], 3)\n",
        "train_uv = train_yuv[:,:,:,1:]\n",
        "\n",
        "test_yuv = tf.image.rgb_to_yuv(class_test_images)\n",
        "test_y = tf.expand_dims(test_yuv[:,:,:,0], 3)\n",
        "test_uv = test_yuv[:,:,:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sym0AJOHb6Mh",
        "colab_type": "code",
        "outputId": "8fd18adb-b960-4a9b-e738-fe88511588e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "# https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder_deconv.py\n",
        "# https://xiangyutang2.github.io/auto-colorization-autoencoders/\n",
        "\n",
        "# Sampling with the reparametrisation trick\n",
        "def sample(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=K.shape(z_mean))\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "def slice_uv(args):\n",
        "    yuv_image = args\n",
        "    return yuv_image[:,:,:,1:]\n",
        "\n",
        "yuv_in = Input(shape=(train_yuv.shape[1], train_yuv.shape[2], train_yuv.shape[3]))\n",
        "uv = Lambda(slice_uv, output_shape=(train_yuv.shape[1], train_yuv.shape[2], 2))(yuv_in)\n",
        "\n",
        "# Define Training Encoder q(z|yuv)\n",
        "layer = Conv2D(filters=8, kernel_size=3, activation='relu', strides=2, padding='same')(uv)\n",
        "layer = Conv2D(filters=16, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=64, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=128, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "shape = K.int_shape(layer) # Shape before flattening\n",
        "\n",
        "# Latent space for encoder\n",
        "layer = Flatten()(layer)\n",
        "layer = Dense(512, activation='relu')(layer)\n",
        "z_mean_training = Dense(LATENT_DIM)(layer)\n",
        "z_log_var_training = Dense(LATENT_DIM)(layer)\n",
        "z_training = Lambda(sample, output_shape=(LATENT_DIM,))([z_mean_training, z_log_var_training]) # Data passable to the decoder\n",
        "\n",
        "# Instantiate encoder \n",
        "encoder_training = Model(yuv_in, z_training, name='training_encoder')\n",
        "encoder_training.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"training_encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_89 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 32, 32, 2)    0           input_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 8)    152         lambda_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 64)     9280        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 2, 2, 128)    73856       conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 512)          0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 512)          262656      flatten_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 2)            1026        dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 2)            1026        dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 2)            0           dense_45[0][0]                   \n",
            "                                                                 dense_46[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 349,164\n",
            "Trainable params: 349,164\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld5oYzuICZFB",
        "colab_type": "code",
        "outputId": "5e00a89d-0d74-417a-e5d1-5c4de00c40f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "y_conditional_in = Input(shape=(train_y.shape[1], train_y.shape[2], train_y.shape[3]))\n",
        "\n",
        "# Define Conditional Encoder p(z|y)\n",
        "layer = Conv2D(filters=8, kernel_size=3, activation='relu', strides=2, padding='same')(y_conditional_in)\n",
        "layer = Conv2D(filters=16, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=64, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2D(filters=128, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "\n",
        "# Latent space for conditional encoder\n",
        "layer = Flatten()(layer)\n",
        "layer = Dense(512, activation='relu')(layer)\n",
        "z_mean_conditional = Dense(LATENT_DIM)(layer)\n",
        "z_log_var_conditional = Dense(LATENT_DIM)(layer)\n",
        "z_conditional = Lambda(sample, output_shape=(LATENT_DIM,))([z_mean_conditional, z_log_var_conditional]) # Data passable to the decoder\n",
        "\n",
        "# Instantiate conditional encoder\n",
        "encoder_conditional = Model(y_conditional_in, z_conditional, name='conditional_encoder')\n",
        "encoder_conditional.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"conditional_encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_90 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 8)    80          input_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 64)     9280        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 2, 2, 128)    73856       conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 512)          0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 512)          262656      flatten_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 2)            1026        dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 2)            1026        dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 2)            0           dense_48[0][0]                   \n",
            "                                                                 dense_49[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 349,092\n",
            "Trainable params: 349,092\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqvYTZmgchIH",
        "colab_type": "code",
        "outputId": "074d7a42-fcf3-4053-9470-f370be0b521b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "y_in = Input(shape=(train_y.shape[1], train_y.shape[2], train_y.shape[3]))\n",
        "\n",
        "# Define Decoder p(yuv|z,y)\n",
        "latent_inputs = Input(shape=(LATENT_DIM,))\n",
        "layer = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "layer = Reshape((shape[1], shape[2], shape[3]))(layer)\n",
        "layer = Conv2DTranspose(filters=128, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=64, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=16, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "layer = Conv2DTranspose(filters=8, kernel_size=3, activation='relu', strides=2, padding='same')(layer)\n",
        "uv_out = Conv2DTranspose(filters=2, kernel_size=3, activation='tanh', padding='same')(layer)\n",
        "concat_outputs = concatenate([uv_out, y_in], 3)\n",
        "layer = Conv2DTranspose(filters=8, kernel_size=3, activation='relu', padding='same')(concat_outputs)\n",
        "mean_yuv = Conv2DTranspose(filters=3, kernel_size=3, activation='tanh', padding='same')(layer)\n",
        "log_sig_sqr_yuv = Conv2DTranspose(filters=3, kernel_size=3, activation='relu', padding='same')(layer)\n",
        "\n",
        "# Instantiate Decoder\n",
        "decoder = Model([latent_inputs, y_in], mean_yuv, name='decoder')\n",
        "decoder.summary()\n",
        "training_yuv_out = decoder([z_training, y_in])\n",
        "conditional_yuv_out = decoder([z_conditional, y_conditional_in])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_92 (InputLayer)           [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 512)          1536        input_92[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 2, 2, 128)    0           dense_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_64 (Conv2DTran (None, 4, 4, 128)    147584      reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_65 (Conv2DTran (None, 8, 8, 64)     73792       conv2d_transpose_64[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_66 (Conv2DTran (None, 16, 16, 16)   9232        conv2d_transpose_65[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_67 (Conv2DTran (None, 32, 32, 8)    1160        conv2d_transpose_66[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_68 (Conv2DTran (None, 32, 32, 2)    146         conv2d_transpose_67[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "input_91 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 3)    0           conv2d_transpose_68[0][0]        \n",
            "                                                                 input_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_69 (Conv2DTran (None, 32, 32, 8)    224         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_70 (Conv2DTran (None, 32, 32, 3)    219         conv2d_transpose_69[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 233,893\n",
            "Trainable params: 233,893\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EymeFZGckiQ",
        "colab_type": "code",
        "outputId": "3b4799e2-8a08-4257-cccf-5a1cb709fd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Instantiate Training VAE\n",
        "# training_yuv_in = Input(shape=(train_yuv.shape[1], train_yuv.shape[2], train_yuv.shape[3]))\n",
        "# training_y_in = Input(shape=(train_y.shape[1], train_y.shape[2], train_y.shape[3]))\n",
        "# training_z = encoder_training(training_yuv_in)\n",
        "# training_yuv_out = decoder([z_training, y_decoder_in])\n",
        "\n",
        "training_vae = Model([yuv_in, y_in], training_yuv_out, name='training_vae')\n",
        "training_vae.summary()\n",
        "\n",
        "# Instantiate Predictor VAE\n",
        "# conditional_y_in = Input(shape=(train_y.shape[1], train_y.shape[2], train_y.shape[3]))\n",
        "# conditional_z = encoder_conditional(y_conditional_in)\n",
        "# conditional_yuv_out = decoder([conditional_z, y_conditional_in])\n",
        "\n",
        "# predictor_vae = Model(y_conditional_in, conditional_yuv_out, name='predictor_vae')\n",
        "# predictor_vae.summary()\n",
        "\n",
        "\n",
        "\n",
        "# vae = Model([yuv_in, y_in, y_conditional_in], yuv_out, name='vae')\n",
        "# vae.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"training_vae\" was not an Input tensor, it was generated by layer input_91.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_91:0\n",
            "Model: \"training_vae\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_89 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 32, 32, 2)    0           input_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 8)    152         lambda_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 64)     9280        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 2, 2, 128)    73856       conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 512)          0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 512)          262656      flatten_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 2)            1026        dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 2)            1026        dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 2)            0           dense_45[0][0]                   \n",
            "                                                                 dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_91 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Model)                 (None, 32, 32, 3)    233893      lambda_19[0][0]                  \n",
            "                                                                 input_91[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 583,057\n",
            "Trainable params: 583,057\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"predictor_vae\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_90 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 8)    80          input_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 8, 8, 16)     1168        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 64)     9280        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 2, 2, 128)    73856       conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 512)          0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 512)          262656      flatten_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 2)            1026        dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 2)            1026        dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 2)            0           dense_48[0][0]                   \n",
            "                                                                 dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Model)                 (None, 32, 32, 3)    233893      lambda_20[0][0]                  \n",
            "                                                                 input_90[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 582,985\n",
            "Trainable params: 582,985\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuSM4_8WfTJD",
        "colab_type": "code",
        "outputId": "c36a5b62-82dc-4cc7-b492-036080abbd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reconstruction_loss = K.sum(mse(yuv_in, training_yuv_out))\n",
        "reconstruction_loss *= (train_yuv.shape[1] * train_yuv.shape[2])\n",
        "kl_loss = 1 + z_log_var_training - K.square(z_mean_training) - K.exp(z_log_var_training)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "training_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "training_vae.add_loss(training_loss)\n",
        "training_vae.compile(optimizer='adam')\n",
        "\n",
        "# # COST FROM RECONSTRUCTION\n",
        "# SMALL_CONSTANT = 1e-6\n",
        "# normalising_factor_uv_vae = - 0.5 * K.log(SMALL_CONSTANT+K.exp(log_sig_sqr_yuv)) - 0.5 * K.log(2 * np.pi)\n",
        "# square_diff_between_mu_and_yuv_vae = K.square(mean_yuv - yuv_in) # yuv_in???\n",
        "# inside_exp_x_vae = -0.5 * (square_diff_between_mu_and_yuv_vae / (SMALL_CONSTANT+K.exp(log_sig_sqr_yuv)))\n",
        "# reconstr_loss_x_vae = -K.sum(normalising_factor_uv_vae + inside_exp_x_vae, 1)\n",
        "# cost_R_vae = K.mean(reconstr_loss_x_vae)\n",
        "\n",
        "# # KL(q(z|uv,y)||p(z|y))\n",
        "# v_mean = z_mean_conditional #2\n",
        "# aux_mean = z_mean_training #1\n",
        "# v_log_sig_sq = K.log(K.exp(z_log_var_conditional)+SMALL_CONSTANT) #2\n",
        "# aux_log_sig_sq = K.log(K.exp(z_log_var_training)+SMALL_CONSTANT) #1\n",
        "# v_log_sig = K.log(K.sqrt(K.exp(v_log_sig_sq))) #2\n",
        "# aux_log_sig = K.log(K.sqrt(K.exp(aux_log_sig_sq))) #1\n",
        "# cost_VAE_a = v_log_sig-aux_log_sig+((K.exp(aux_log_sig_sq)+K.square(aux_mean-v_mean))/(2*K.exp(v_log_sig_sq)))-0.5\n",
        "# cost_VAE_b = K.sum(cost_VAE_a,1)\n",
        "# KL_vae = K.mean(cost_VAE_b)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5mLOER-hjnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "47b7361b-b1ca-4929-feda-a0fa1bb58ba4"
      },
      "source": [
        "# Training VAE fitting\n",
        "history = training_vae.fit([train_yuv, train_y], shuffle=False, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=([test_yuv, test_y], None))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5000 samples, validate on 1000 samples\n",
            "Epoch 1/5\n",
            "5000/5000 [==============================] - 2s 326us/sample - loss: 3225237.8175 - val_loss: 1128896.1500\n",
            "Epoch 2/5\n",
            "5000/5000 [==============================] - 1s 125us/sample - loss: 899291.2575 - val_loss: 733681.2250\n",
            "Epoch 3/5\n",
            "5000/5000 [==============================] - 1s 124us/sample - loss: 583395.5644 - val_loss: 469133.5156\n",
            "Epoch 4/5\n",
            "5000/5000 [==============================] - 1s 134us/sample - loss: 400490.1869 - val_loss: 356731.3344\n",
            "Epoch 5/5\n",
            "5000/5000 [==============================] - 1s 124us/sample - loss: 323863.0994 - val_loss: 312162.0672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8sV7ydLU46g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "d9dc7535-4320-4980-aa96-a692efc5fb4c"
      },
      "source": [
        "conditional_loss = K.sum(mse(z_training, z_conditional))\n",
        "encoder_conditional.add_loss(conditional_loss)\n",
        "encoder_conditional.compile(optimizer='adam')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-7e66747586f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconditional_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_conditional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_conditional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconditional_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mencoder_conditional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_loss\u001b[0;34m(self, losses, inputs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msymbolic_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbolic_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_graph_network'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m           \u001b[0;31m# Possible a loss was added in a Layer's `build`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_graph_network_add_loss\u001b[0;34m(self, symbolic_loss)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m     \u001b[0mnew_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_subgraph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m     \u001b[0;31m# Losses must be keyed on inputs no matter what in order to be supported in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;31m# DistributionStrategy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_subgraph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1702\u001b[0m   \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m   \u001b[0;31m# Keep only nodes and layers in the topology betweeen inputs and outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_89:0\", shape=(None, 32, 32, 3), dtype=float32) at layer \"input_89\". The following previous layers were accessed without issue: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYe_ApQ8xAp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(38, 9))\n",
        "\n",
        "fig.add_subplot(1,4,1)\n",
        "plt.title(\"Fidelity\")\n",
        "plt.plot(history.history[\"loss\"][5:], label=\"Training Image Loss\")\n",
        "plt.plot(history.history[\"val_loss\"][5:], label=\"Testing Image Loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnEmo9Mzih9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = vae.predict([train_yuv, train_y])\n",
        "\n",
        "output_count = 12\n",
        "index_offset = 20\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"Original\")\n",
        "  plt.imshow(class_train_images[i+index_offset])\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"Output\")\n",
        "  plt.imshow(tf.image.yuv_to_rgb(result[i+index_offset]))\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"U original\")\n",
        "  plt.imshow(train_yuv[i+index_offset,:,:,1])\n",
        "  \n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"U output\")\n",
        "  plt.imshow(result[i+index_offset,:,:,1])\n",
        "  \n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"V original\")\n",
        "  plt.imshow(train_yuv[i+index_offset,:,:,2])\n",
        "  \n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"V output\")\n",
        "  plt.imshow(result[i+index_offset,:,:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zWwRU-PsNfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = vae.predict([train_yuv[test_y.shape[0]:test_y.shape[0]*2], test_y])\n",
        "\n",
        "output_count = 12\n",
        "index_offset = 20\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"Original\")\n",
        "  plt.imshow(class_test_images[i+index_offset])\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"Output\")\n",
        "  plt.imshow(tf.image.yuv_to_rgb(result[i+index_offset]))\n",
        "\n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"U original\")\n",
        "  plt.imshow(test_yuv[i+index_offset,:,:,1])\n",
        "  \n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"U output\")\n",
        "  plt.imshow(result[i+index_offset,:,:,1])\n",
        "  \n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"V original\")\n",
        "  plt.imshow(test_yuv[i+index_offset,:,:,2])\n",
        "  \n",
        "fig = plt.figure(figsize=(39, 39))\n",
        "for i in range(output_count):\n",
        "  fig.add_subplot(1,output_count,i+1)\n",
        "  plt.title(\"V output\")\n",
        "  plt.imshow(result[i+index_offset,:,:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZAkLYqM_fLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}